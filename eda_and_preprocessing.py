# -*- coding: utf-8 -*-
"""EDA and Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gea3u6PjbATm08iH6GqSimzCLfkHunbm
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler

# Load the dataset
file_path = "/content/Employee.csv"
df = pd.read_csv(file_path)

"""# **Question 1**"""

print("Initial Dataset Info:")
df.info()

print("\nFirst 5 Rows:")
print(df.head())

print("\nThe number of null values coloumn wise is:","\n",df.isnull().sum())

print("\nUnique Values in Each Column:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

print("\nStatistical Summary:")
print(df.describe())

df.columns = [col.strip().lower().replace(" ", "_") for col in df.columns]

"""# **Question 2**"""

from scipy.stats import skew, kurtosis

# Select numerical columns for analysis
num_cols = ['age', 'salary']

# Analyze each column
for col in num_cols:
    print(f"\nColumn: {col}")
    print(f"Mean: {df[col].mean():.2f}")
    print(f"Median: {df[col].median():.2f}")
    print(f"Mode: {df[col].mode()[0]:.2f}")
    print(f"Skewness: {skew(df[col]):.2f}")
    print(f"Kurtosis: {kurtosis(df[col]):.2f}")

    # Visualizing Distribution to Determine Best Imputation Method
    plt.figure(figsize=(8, 5))
    sns.histplot(df[col], kde=True, bins=30, color='skyblue')
    plt.axvline(df[col].mean(), color='red', linestyle='dashed', label='Mean')
    plt.axvline(df[col].median(), color='green', linestyle='dashed', label='Median')
    plt.axvline(df[col].mode()[0], color='blue', linestyle='dashed', label='Mode')
    plt.legend()
    plt.title(f"Distribution of {col} - Checking for Skewness")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.grid(True)
    plt.show()

df.loc[df['age'] == 0, 'age'] = np.nan

df.loc[:, 'salary'] = df['salary'].fillna(df['salary'].median())
df.loc[:, 'age'] = df['age'].fillna(df['age'].median())
df.loc[:, 'company'] = df['company'].fillna(df['company'].mode()[0])
df.loc[:, 'place'] = df['place'].fillna(df['place'].mode()[0])

df.drop_duplicates(inplace=True)

def plot_distribution(df, column):
    plt.figure(figsize=(8,5))
    sns.histplot(df[column], bins=30, kde=True, color='skyblue', edgecolor='black')


    mean_val = df[column].mean()
    median_val = df[column].median()
    mode_val = df[column].mode()[0]

    plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=2, label=f"Mean: {mean_val:.2f}")
    plt.axvline(median_val, color='green', linestyle='dashed', linewidth=2, label=f"Median: {median_val:.2f}")
    plt.axvline(mode_val, color='blue', linestyle='dashed', linewidth=2, label=f"Mode: {mode_val:.2f}")

    plt.title(f"Distribution of {column} - Checking for Skewness After Imputation")
    plt.xlabel(column)
    plt.ylabel("Frequency")
    plt.legend()
    plt.show()


plot_distribution(df, "age")

plot_distribution(df, "salary")

for col in num_cols:
    print(f"\nColumn: {col}")
    print(f"Mean: {df[col].mean():.2f}")
    print(f"Median: {df[col].median():.2f}")
    print(f"Mode: {df[col].mode()[0]:.2f}")
    print(f"Skewness: {skew(df[col]):.2f}")
    print(f"Kurtosis: {kurtosis(df[col]):.2f}")

from scipy.stats import zscore, skew, kurtosis
mean_val = df[col].mean()
std_dev = df[col].std()
z_scores = np.abs((df[col] - mean_val) / std_dev)
outlier_threshold = 3
trimmed_df_mean_std = df[z_scores < outlier_threshold].copy()


lower_bound = df[col].quantile(0.01)
upper_bound = df[col].quantile(0.99)
df_percentile = df.copy()
df_percentile[col] = np.clip(df[col], lower_bound, upper_bound)


Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1
lower_bound_iqr = Q1 - 1.5 * IQR
upper_bound_iqr = Q3 + 1.5 * IQR
trimmed_df_iqr = df[(df[col] >= lower_bound_iqr) & (df[col] <= upper_bound_iqr)].copy()


from scipy.stats import zscore
z_scores_all = np.abs(zscore(df[col]))
df_zscore = df.copy()
df_zscore[col] = np.where(z_scores_all > 3, df[col].median(), df[col])


print(f"Original count: {df[col].count()}")
print(f"Mean-Std Trim count: {trimmed_df_mean_std[col].count()}")
print(f"Percentile Cap count: {df_percentile[col].count()}")
print(f"IQR Trim count: {trimmed_df_iqr[col].count()}")
print(f"Z-Score Impute count: {df_zscore[col].count()}")


plt.figure(figsize=(12, 6))
sns.set_theme(style="whitegrid")


df_combined = pd.DataFrame({
    "Original": np.log1p(df[col].dropna()),
    "Mean-Std (Trim)": np.log1p(trimmed_df_mean_std[col].dropna()),
    "Percentile (Cap)": np.log1p(df_percentile[col].dropna()),
    "IQR (Trim)": np.log1p(trimmed_df_iqr[col].dropna()),
    "Z-Score (Impute)": np.log1p(df_zscore[col].dropna())
})

df_melted = df_combined.melt(var_name="Method", value_name="Log Price Per Sqft")


sns.boxplot(
    x="Method",
    y="Log Price Per Sqft",
    hue="Method",
    data=df_melted,
    palette="Set2",
    linewidth=1.2,
    width=0.5,
    legend=False
)

plt.title("Comparison of Outlier Removal Methods (Log Transformed)", fontsize=14, fontweight='bold')
plt.xlabel("Outlier Removal Method", fontsize=12)
plt.ylabel("Log Price Per Sqft", fontsize=12)

plt.xticks(rotation=0, fontsize=11)
plt.grid(axis="y", linestyle="--", alpha=0.7)

plt.show()

"""Either dataset has minimal or none outliers or no significant outliers. IQR (Interquartile Range) is typically the safest choice here."""

def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

df = remove_outliers_iqr(df, 'salary')

"""# **Question 3**"""

# Filtering Data
df_filtered = df[(df['age'] > 40) & (df['salary'] < 5000)]
print("\nFiltered Data (Age > 40 and Salary < 5000):")
print(df_filtered)

plt.figure(figsize=(8, 5))
sns.scatterplot(x=df['age'], y=df['salary'], color="purple", alpha=0.7)
plt.xlabel("Age")
plt.ylabel("Salary")
plt.title("Age vs Salary")
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 5))
sns.countplot(data=df, y="place", order=df["place"].value_counts().index, palette="viridis", hue="place", legend=False)
plt.xlabel("Count")
plt.ylabel("Place")
plt.title("Number of People from Each Place")
plt.show()

"""# **Question 4**"""

categorical_cols = ['company', 'place', 'country']
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

"""# **Question 5**"""

scaler_standard = StandardScaler()
scaler_minmax = MinMaxScaler()

numeric_cols = ['age', 'salary']
df_standard_scaled = scaler_standard.fit_transform(df_encoded[numeric_cols])
df_minmax_scaled = scaler_minmax.fit_transform(df_encoded[numeric_cols])

df_standard_scaled = pd.DataFrame(df_standard_scaled, columns=[f"{col}_standard" for col in numeric_cols])
df_minmax_scaled = pd.DataFrame(df_minmax_scaled, columns=[f"{col}_minmax" for col in numeric_cols])

df_final = pd.concat([df_encoded, df_standard_scaled, df_minmax_scaled], axis=1)

print("\nFinal Processed Dataset:")
print(df_final.head())

df_final.to_csv("Processed_Employee.csv", index=False)
print("\nProcessed dataset saved as 'Processed_Employee.csv' âœ…")